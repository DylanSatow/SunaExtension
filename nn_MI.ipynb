{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "from scipy.special import digamma\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.neighbors import KDTree, NearestNeighbors\n",
    "\n",
    "def std_matrix(X):\n",
    "    \"\"\"Standardize matrix by centering and scaling by standard deviation\"\"\"\n",
    "    x_means = torch.mean(X, dim=0)\n",
    "    x_stds = torch.std(X, dim=0)\n",
    "    return (X - x_means) / x_stds\n",
    "\n",
    "class GPUMIComputer:\n",
    "    def __init__(self, n_neighbors=3, device='cuda'):\n",
    "        self.k = n_neighbors\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda'\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = 'mps'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "            print(\"You won't be able to train the RNN decoder on a CPU, unfortunately.\")\n",
    "        print(self.device)\n",
    "\n",
    "    def compute_radius(self, X, Y):\n",
    "        \"\"\"Compute k-nearest neighbor radius efficiently on GPU\"\"\"\n",
    "        n, m = X.shape\n",
    "        points = torch.stack((X, Y), dim=2).to(self.device)\n",
    "        \n",
    "        # Compute pairwise distances using batched operations\n",
    "        batch_size = 1000  # Adjust based on GPU memory\n",
    "        distances = torch.zeros(n, n, device=self.device)\n",
    "        \n",
    "        for i in range(0, n, batch_size):\n",
    "            batch_end = min(i + batch_size, n)\n",
    "            batch = points[i:batch_end]\n",
    "            \n",
    "            # Compute distances for current batch\n",
    "            diffs = batch.unsqueeze(1) - points.unsqueeze(0)\n",
    "            batch_distances = torch.max(torch.abs(diffs), dim=2)[0]\n",
    "            distances[i:batch_end] = batch_distances\n",
    "\n",
    "        # Get kth smallest distance for each point\n",
    "        k_distances, _ = torch.topk(distances, k=self.k+1, dim=1, largest=False)\n",
    "        return k_distances[:, -1]\n",
    "\n",
    "    def compute_counts(self, X, Y, radius):\n",
    "        \"\"\"Count points within radius using optimized GPU operations\"\"\"\n",
    "        n, m = X.shape\n",
    "        radius = radius.unsqueeze(1)\n",
    "\n",
    "        # Compute counts in batches\n",
    "        batch_size = 1000\n",
    "        nx = torch.zeros(n, device=self.device)\n",
    "        ny = torch.zeros(n, device=self.device)\n",
    "\n",
    "        for i in range(0, n, batch_size):\n",
    "            batch_end = min(i + batch_size, n)\n",
    "            batch_radius = radius[i:batch_end]\n",
    "\n",
    "            # X counts\n",
    "            X_diffs = torch.abs(X[i:batch_end].unsqueeze(1) - X.unsqueeze(0))\n",
    "            nx[i:batch_end] = (X_diffs < batch_radius).sum(dim=1) - 1\n",
    "\n",
    "            # Y counts\n",
    "            Y_diffs = torch.abs(Y[i:batch_end].unsqueeze(1) - Y.unsqueeze(0))\n",
    "            ny[i:batch_end] = (Y_diffs < batch_radius).sum(dim=1) - 1\n",
    "\n",
    "        return nx, ny\n",
    "\n",
    "    def compute_MI(self, X, Y):\n",
    "        \"\"\"Compute mutual information with GPU acceleration\"\"\"\n",
    "        # Move data to GPU if needed\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.tensor(X, device=self.device)\n",
    "        if not isinstance(Y, torch.Tensor):\n",
    "            Y = torch.tensor(Y, device=self.device)\n",
    "\n",
    "        # Standardize inputs\n",
    "        X = std_matrix(X)\n",
    "        Y = std_matrix(Y)\n",
    "\n",
    "        # Compute radius and counts\n",
    "        radius = self.compute_radius(X, Y)\n",
    "        nx, ny = self.compute_counts(X, Y, radius)\n",
    "\n",
    "        # Calculate MI using digamma function\n",
    "        mi = (\n",
    "            torch.digamma(torch.tensor(X.shape[0], device=self.device))\n",
    "            + torch.digamma(torch.tensor(self.k, device=self.device))\n",
    "            - torch.mean(torch.digamma(nx + 1))\n",
    "            - torch.mean(torch.digamma(ny + 1))\n",
    "        )\n",
    "        return torch.clamp(mi, min=0)\n",
    "\n",
    "class CPUMIComputer:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        self.k = n_neighbors\n",
    "        self.threads = mp.cpu_count()\n",
    "\n",
    "    def process_column(self, X, Y, n_neighbors, col_idx):\n",
    "        \"\"\"Process a single column for MI computation\"\"\"\n",
    "        col_X = X[:, col_idx:col_idx+1]\n",
    "        col_Y = Y[:, col_idx:col_idx+1]\n",
    "\n",
    "        # Use sklearn's NearestNeighbors for efficient radius computation\n",
    "        xy = np.hstack((col_X, col_Y))\n",
    "        nn = NearestNeighbors(metric=\"chebyshev\", n_neighbors=self.k)\n",
    "        nn.fit(xy)\n",
    "        radius = np.nextafter(nn.kneighbors()[0][:, -1], 0)\n",
    "\n",
    "        # Use KDTree for efficient counting\n",
    "        kdx = KDTree(col_X, metric=\"chebyshev\")\n",
    "        kdy = KDTree(col_Y, metric=\"chebyshev\")\n",
    "        nx = kdx.query_radius(col_X, radius, count_only=True, return_distance=False) - 1\n",
    "        ny = kdy.query_radius(col_Y, radius, count_only=True, return_distance=False) - 1\n",
    "\n",
    "        mi = (\n",
    "            digamma(len(col_X))\n",
    "            + digamma(n_neighbors)\n",
    "            - np.mean(digamma(nx + 1))\n",
    "            - np.mean(digamma(ny + 1))\n",
    "        )\n",
    "        return col_idx, max(0, mi)\n",
    "\n",
    "    def compute_MI(self, X, Y):\n",
    "        \"\"\"Compute MI using parallel CPU processing\"\"\"\n",
    "        n_cols = X.shape[1]\n",
    "        mi_results = [None] * n_cols\n",
    "\n",
    "        # Use ThreadPoolExecutor for parallel processing\n",
    "        with ThreadPoolExecutor(max_workers=self.threads) as executor:\n",
    "            futures = []\n",
    "            for i in range(n_cols):\n",
    "                future = executor.submit(self.process_column, X, Y, self.k, i)\n",
    "                futures.append(future)\n",
    "\n",
    "            for future in futures:\n",
    "                col_idx, mi = future.result()\n",
    "                mi_results[col_idx] = mi\n",
    "\n",
    "        return mi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Mutual Information: 8.984471321105957\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "X = torch.randn(1000)\n",
    "Y = torch.randn(1000)\n",
    "\n",
    "mi_computer = OptimizedMIComputer(n_neighbors=3, batch_size=1000)\n",
    "mi = mi_computer.compute_MI(X, Y)\n",
    "print(f\"Mutual Information: {mi.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
